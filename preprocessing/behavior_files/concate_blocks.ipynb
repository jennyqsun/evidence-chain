{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subsequently save a concatenante file under rechain-beh called all_df_concat.csv '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hdf5storage\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "'''this script concate each block per subject to a file wihthin subject called s103_df_concat.csv'''\n",
    "\n",
    "'''subsequently save a concatenante file under rechain-beh called all_df_concat.csv '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global setting f\n",
    "plt.rcParams.update({'font.size': 17})\n",
    "mpl.rcParams['lines.markersize'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top level dir \n",
    "# \n",
    "\n",
    "PROJECT_DIR = \"/data/rwchain-all/round2\"\n",
    "BEH_DIR = os.path.join(PROJECT_DIR, \"rwchain-beh/data\")\n",
    "EEG_DIR = os.path.join(PROJECT_DIR, \"rwchain-eeg\")\n",
    "\n",
    "list_of_subj = os.listdir(BEH_DIR)\n",
    "list_of_subj.sort()\n",
    "# list_of_subj = [list_of_subj[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s102\n",
      "5 files found session 1\n",
      "10 files found session 2\n",
      "s103\n",
      "10 files found session 1\n",
      "10 files found session 2\n",
      "s105\n",
      "9 files found session 1\n",
      "10 files found session 2\n",
      "s106\n",
      "10 files found session 1\n",
      "10 files found session 2\n",
      "s107\n",
      "10 files found session 1\n",
      "10 files found session 2\n",
      "s108\n",
      "5 files found session 1\n",
      "10 files found session 2\n",
      "s109\n",
      "10 files found session 1\n",
      "5 files found session 2\n",
      "missing files!\n",
      "s110\n",
      "10 files found session 1\n",
      "10 files found session 2\n",
      "s112\n",
      "10 files found session 1\n",
      "10 files found session 2\n",
      "s113\n",
      "10 files found session 1\n",
      "10 files found session 2\n"
     ]
    }
   ],
   "source": [
    "# read and concatenance .csv file of the behavioral data\n",
    "for subj in list_of_subj:\n",
    "    BEH_DIR_SUBJ = os.path.join(BEH_DIR, subj)\n",
    "    flist_beh = os.listdir(BEH_DIR_SUBJ)\n",
    "\n",
    "    onlyfile_s1 = [f for f in flist_beh if subj in f and 'csv' in f and 'ses1' in f]\n",
    "    onlyfile_s2 = [f for f in flist_beh if subj in f and 'csv' in f and 'ses2' in f]\n",
    "\n",
    "    onlyfile_s1.sort()\n",
    "    onlyfile_s2.sort()\n",
    "    print(subj)\n",
    "    # print(onlyfile_s1)\n",
    "    # print(onlyfile_s2)\n",
    "    print(len(onlyfile_s1), 'files found session 1')\n",
    "    print(len(onlyfile_s2), 'files found session 2')\n",
    "    if len(onlyfile_s2) != 10:\n",
    "        print('missing files!')\n",
    "    df = []\n",
    "\n",
    "\n",
    "    for f in onlyfile_s1:\n",
    "        fname = os.path.join(BEH_DIR_SUBJ, f)\n",
    "        blockdf = pd.read_csv(fname)\n",
    "        blocknum = f[16]\n",
    "        blockdf['block'] =  blocknum\n",
    "        block_string = f'ses1_block_{blocknum}'\n",
    "        fname_chain = [f for f in flist_beh if subj in f and 'chains' in f and block_string in f]\n",
    "        chain_array = pd.read_pickle(os.path.join(BEH_DIR_SUBJ, fname_chain[0]))\n",
    "        blockdf['sequence_clean'] = chain_array.tolist()\n",
    "        blockdf['sid'] = subj\n",
    "        df.append(blockdf)\n",
    "    for f in onlyfile_s2:\n",
    "        fname = os.path.join(BEH_DIR_SUBJ, f)\n",
    "        blockdf = pd.read_csv(fname)\n",
    "        blocknum = f[16]\n",
    "        blockdf['block'] =  blocknum\n",
    "        block_string = f'ses2_block_{blocknum}'\n",
    "        fname_chain = [f for f in flist_beh if subj in f and 'chains' in f and block_string in f]\n",
    "        chain_array = pd.read_pickle(os.path.join(BEH_DIR_SUBJ, fname_chain[0]))\n",
    "        blockdf['sequence_clean'] = chain_array.tolist()\n",
    "        blockdf['sid'] = subj\n",
    "        df.append(blockdf)\n",
    "    df = pd.concat(df)\n",
    "    file_path = os.path.join(BEH_DIR_SUBJ, f'{subj}_df_concat.csv')\n",
    "    df.to_csv(file_path, index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s113_df_concat.csv',\n",
       " 's113_ses1_block_7.csv',\n",
       " 's113_ses2_block_8.csv',\n",
       " 's113_ses2_block_1_chains',\n",
       " 's113_ses1_block_4_chains',\n",
       " 's113_ses1_block_5.csv',\n",
       " 's113_ses2_block_7.csv',\n",
       " 's113_ses1_block_3.csv',\n",
       " 's113_ses2_block_1.csv',\n",
       " 's113_ses1_block_4.csv',\n",
       " 's113_ses1_block_6.csv',\n",
       " 's113_ses1_block_0.csv',\n",
       " 's113_ses2_block_0_chains',\n",
       " 's113_ses2_block_8_chains',\n",
       " 's113_ses2_block_9_chains',\n",
       " 's113_ses2_block_6.csv',\n",
       " 's113_ses2_block_9.csv',\n",
       " 's113_ses2_block_6_chains',\n",
       " 's113_ses2_block_3_chains',\n",
       " 's113_ses1_block_7_chains',\n",
       " 's113_ses2_block_0.csv',\n",
       " 's113_ses1_block_1_chains',\n",
       " 's113_ses1_block_2_chains',\n",
       " 's113_ses1_block_6_chains',\n",
       " 's113_ses2_block_4_chains',\n",
       " 's113_ses1_block_9_chains',\n",
       " 's113_ses1_block_5_chains',\n",
       " 's113_ses1_block_3_chains',\n",
       " 's113_ses2_block_3.csv',\n",
       " 's113_ses2_block_5_chains',\n",
       " 's113_ses1_block_9.csv',\n",
       " 's113_ses1_block_1.csv',\n",
       " 'training',\n",
       " 's113_ses1_block_8_chains',\n",
       " 's113_ses1_block_8.csv',\n",
       " 's113_ses1_block_2.csv',\n",
       " 's113_ses2_block_5.csv',\n",
       " 's113_ses2_block_7_chains',\n",
       " 's113_ses2_block_4.csv',\n",
       " 's113_ses1_block_0_chains',\n",
       " 's113_ses2_block_2_chains',\n",
       " 's113_ses2_block_2.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flist_beh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and concatenance .csv file of the behavioral data\n",
    "df_all = []\n",
    "for subj in list_of_subj:\n",
    "\n",
    "    \n",
    "    BEH_DIR_SUBJ = os.path.join(BEH_DIR, subj)\n",
    "    fname = os.path.join(BEH_DIR_SUBJ, f'{subj}_df_concat.csv')\n",
    "\n",
    "    df = pd.read_csv(fname)\n",
    "    df_all.append(df)\n",
    "df_all = pd.concat(df_all)\n",
    "file_path = os.path.join(PROJECT_DIR, 'rwchain-beh', 'combined', 'all_df_concat.csv')\n",
    "df_all.to_csv(file_path, index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "echain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
